# -*- coding: utf-8 -*-
"""predicting-walmart-sales.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11lyXVOdfebgfhoJdS_xBpIV_WjYM5Klv
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import os
import sklearn
import matplotlib.pyplot as plt
import seaborn as sns.
# %matplotlib inline

df = pd.read_csv('Walmart.csv')
df.head()

"""**1. DATA EXPLORATION**"""

df.info()

df.describe()

df.isnull().sum()

df['Date'] = pd.to_datetime(df['Date'])
df['Day'] = df['Date'].dt.weekday
df['Month'] = df['Date'].dt.month
df['Year']  = df['Date'].dt.year
df.drop('Date',axis=1,inplace=True)
df.head()

df.shape

df12= df.copy()

"""2. **Exploratory Data Analysis**"""

df.head()

#visualization of data 
import missingno as msgn
msgn.matrix(df)

# converting days and months from numerics to categories
days = {0:'Sunday',1:'Monday',2:'Tuesday',3:'Wednesday',4:'Thursday',5: 'Friday',6:'Saturday'}
df['Day'] = df['Day'].map(days)
months={1:'January',2:'February',3:'March',4:'April',5:'May',6:'June',7:'July',8:'August',9:'September',10:'October',11:'Novemenber',12:'December'}
df['Month']= df['Month'].map(months)
df.head()

for i in ['Store','Fuel_Price','Unemployment','Day','Month','Year']:
    print(f'{i}: {df[i].nunique()}')

sns.countplot(df['Year'],order=df['Year'].value_counts().index)

plt.figure(figsize=(8,4))
sns.countplot(df['Day'],order=df['Day'].value_counts().index)

plt.figure(figsize=(12,8))
sns.countplot(df['Month'],order= df['Month'].value_counts().index)

df.groupby('Year')['Weekly_Sales'].sum()

plt.pie(df.groupby('Year')['Weekly_Sales'].sum(),labels=df['Year'].unique(),autopct='%1.2f%%',colors=['hotpink','green','violet'])
plt.title('Annual Sales')

df2 = df.groupby('Day')['Weekly_Sales'].sum().reset_index()
df2.head(10)

plt.figure(figsize=(10,8))
plt.pie(df2['Weekly_Sales'],labels= df2['Day'],autopct='%1.2f%%')

df3 = df.groupby('Month')['Weekly_Sales'].sum().reset_index()

df3.head()

plt.figure(figsize=(10,10))
plt.pie(df3['Weekly_Sales'],labels=df3['Month'],autopct='%1.2f%%')

df4 = df.groupby('Holiday_Flag')['Weekly_Sales'].sum().reset_index()
plt.pie(df4['Weekly_Sales'],labels= ['Non Special Holiday Week','Special Holiday Week'],autopct='%1.2f%%',startangle=90,explode=[0,0.3],shadow=True,colors=['hotpink','green'])

df.groupby('Store')['Weekly_Sales'].count().reset_index()

df.groupby('Store')['Weekly_Sales'].sum().reset_index()

df.groupby('Store')['Weekly_Sales'].sum().max()

"""#### **Observation:**
* 2011 has recorded highest number of sales then followed by 2010 and 2012.
* More than 50% of sales happen on Thursday.
* Highest sales are recorded in April then followed by May, October, December ,September although their is little variance.
* Most sales comes on non special holiday week which makes sense people may not want to spend their special grocery shopping they would probably shop before to celebrate their special holiday.
* All stores have equal number of sales yet store 20 has recorded highest sales.

# Distributions
"""

fig = plt.figure(figsize=(25,25))
ax = fig.gca()
df.hist(ax=ax)
plt.tight_layout

sns.distplot(df['Weekly_Sales'],kde=True)

sns.displot(df['Temperature'],kde=True)

sns.boxplot(df['Temperature'])

sns.displot(df['Fuel_Price'],kde=True)

sns.boxplot(df['Fuel_Price'])

sns.displot(df['Unemployment'],kde=True)

sns.boxplot(df['Unemployment'])

sns.distplot(df['CPI'],kde=True)

sns.boxplot(df['CPI'])

"""### Applying Power Transformation on numeric columns 

"""

cols =['Temperature','Fuel_Price','CPI','Unemployment']
df_numeric = df[cols]
from sklearn.preprocessing import PowerTransformer

pt = PowerTransformer(standardize=True)
df_transformed = pd.DataFrame(pt.fit_transform(df_numeric),columns=cols)

pd.DataFrame({'cols':cols, 'box-cox lamda': pt.lambdas_})

for col in cols:
    df[col] = df_transformed[col]
    
    
df.head()

"""# Data Preprocessing
* Removal of Outliers - Unemployment 
* Encoding - categorical varaible - Target Encoding
 
"""

df.shape

Q1 = df['Unemployment'].quantile(0.25)
Q3 = df['Unemployment'].quantile(0.75)
IQR = Q3-Q1

df = df[df['Unemployment'] >= Q1-1.5*(IQR)]
df = df[df['Unemployment'] <= Q3+1.5*(IQR)]
df.shape

Q1 = df['Temperature'].quantile(0.25)
Q3 = df['Temperature'].quantile(0.75)
IQR = Q3-Q1

df = df[df['Temperature'] >= Q1-1.5*(IQR)]

df = df[df['Temperature'] <= Q3+1.5*(IQR)]
df.shape

"""### Ploting boxplots after removing outliers"""

sns.boxplot(df['Temperature'])

sns.boxplot(df['Unemployment'])

"""#### **Encoding**

"""

# tranformation of distributions
# how to find multi colinearity and use feature selection

"""# Data Manipulation
* Encoding - using column transormer 
* Scaling
* Splitting data
"""

# Target guided encoding of day ,month, year column - ranked as per the sales
tge= {'Sunday':5,'Monday':3, 'Tuesday':0, 'Wednesday':4, 'Thursday':6,  'Friday':1,'Saturday':2}
df['Day'] = df['Day'].map(tge)
df.head()

yr = {2010:1, 2011:2, 2012:0}
df['Year'] = df['Year'].map(yr)
df.head()

mn = {'January':1,'February':3,'March':4,'April':12,'May':11,'June':6,'July':8,'August':5,'September':7,'October':10,'Novemenber':2,'December':9}
df['Month'] = df['Month'].map(mn)
df.head()

X = df.drop(['Weekly_Sales'],axis=1)
Y = df['Weekly_Sales']

from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.4,random_state=42)

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
transformer = ColumnTransformer(transformers=[('tf',OneHotEncoder(sparse=False,drop='first'),['Store'])],remainder='passthrough')

X_train= transformer.fit_transform(X_train)
X_test = transformer.transform(X_test)

"""### Scaling """

#from sklearn.preprocessing import RobustScaler
#std = RobustScaler()
#X_train = std.fit_transform(X_train)
#X_test = std.transform(X_test)

"""# Feature Selection"""

plt.figure(figsize=(12,12))
sns.heatmap(df.corr(),annot=True)
plt.title('Correlation Matrix')

# feature selection has to be performed

"""# Predictive Modelling

#### Regression Metrics 
1. MSE
2. MAE
3. R2 SCORE
4. RMSE
5. Median ABsolute Error
6. Predictions Error Rate
7. Almost Correct Predictions Error Rate
"""

from sklearn.linear_model import LinearRegression,Lasso,Ridge,ElasticNet
from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score

def pred_model(model,X_train,Y_train,X_test,Y_test):
    c = model()
    c.fit(X_train,Y_train)
    y_pred = c.predict(X_test)
    print(model)
    print(f'MSE: {mean_squared_error(Y_test,y_pred)}')
    print(f'MAE: {mean_absolute_error(Y_test,y_pred)}')
    print(f'R2 : {r2_score(Y_test,y_pred)}')
    




pred_model(LinearRegression,X_train,Y_train,X_test,Y_test)

pred_model(Lasso,X_train,Y_train,X_test,Y_test)

pred_model(Ridge,X_train,Y_train,X_test,Y_test)

pred_model(RandomForestRegressor,X_train,Y_train,X_test,Y_test)

pred_model(ElasticNet,X_train,Y_train,X_test,Y_test)